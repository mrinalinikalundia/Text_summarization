# -*- coding: utf-8 -*-
"""Text Summarization using spacy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aOVEc3jp7D03Y9lzaBSX6gQX4QjWiGC-
"""

!pip install -U spacy
!python -m spacy download en_core_web_sm

import spacy
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation

stopwords= list(STOP_WORDS)

nlp=spacy.load('en_core_web_sm')

with open('/content/boota-singh-vs-state-of-haryana-ll-2021-sc-218 - Dhiraj Kumar Sharma.txt','r')as file:
  data=file.read().replace('\n', '')

doc=nlp(data)

tokens=[token.text for token in doc]
print(tokens)

punctuation=punctuation + '\n'

word_frequencies={}
for word in doc:
  if word.text.lower() not in stopwords:
    if word.text.lower() not in punctuation:
      if word.text not in word_frequencies.keys():
        word_frequencies[word.text]=1
      else:
        word_frequencies[word.text] += 1

print(word_frequencies)

max_frequencies=max(word_frequencies.values())

max_frequencies

for word in word_frequencies.keys():
  word_frequencies[word]=word_frequencies[word]/max_frequencies

print(word_frequencies)

sentence_tokens=[sent for sent in doc.sents]
sentence_tokens

sentence_scores={}
for sent in sentence_tokens:
  for word in sent:
    if word.text.lower() in word_frequencies.keys():
      if sent not in sentence_scores.keys():
        sentence_scores[sent]=word_frequencies[word.text.lower()]
      else:
        sentence_scores[sent]+=word_frequencies[word.text.lower()]

sentence_scores

from heapq import nlargest

select_length=int(len(sentence_tokens)*0.2)
select_length

summary=nlargest(select_length,sentence_scores,key=sentence_scores.get)

summary

final_summary=[word.text for word in summary]

summary=''.join(final_summary)

summary

data

len(data)

len(summary)